{
 "cells": [
  {
   "cell_type": "code",
   "id": "c0bd05f696b63670",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:31:54.405487Z",
     "start_time": "2024-11-22T15:31:52.117406Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Charger un modèle pré-entraîné (ResNet50, par exemple)\n",
    "model = ResNet50(weights='imagenet', include_top=False, pooling='avg')"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T15:34:20.914610Z",
     "start_time": "2024-11-22T15:34:20.222895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fonction pour extraire les embeddings d'une image\n",
    "def get_embedding(image_path):\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convertir en RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Redimensionner pour correspondre à l'entrée du modèle\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # Prétraitement de l'image\n",
    "    image = preprocess_input(np.expand_dims(image, axis=0))\n",
    "    # Obtenir les embeddings\n",
    "    embedding = model.predict(image)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# Base de données : Dictionnaire avec noms et chemins des photos\n",
    "database = {\n",
    "    \"Clem\": \"contacts_photos/Clem.jpg\",\n",
    "    \"Jerem\": \"contacts_photos/Jerem.jpg\",\n",
    "}\n",
    "\n",
    "# Extraire les embeddings pour la base de données\n",
    "embeddings_db = {}\n",
    "for name, photo_path in database.items():\n",
    "    embeddings_db[name] = get_embedding(photo_path)\n",
    "\n",
    "\n",
    "# Fonction pour trouver la correspondance la plus proche\n",
    "def find_most_similar(new_image_path, embeddings_db):\n",
    "    # Obtenir l'embedding de la nouvelle image\n",
    "    new_embedding = get_embedding(new_image_path)\n",
    "    # Calculer les similarités\n",
    "    similarities = {\n",
    "        name: cosine_similarity(new_embedding, embedding)[0][0]\n",
    "        for name, embedding in embeddings_db.items()\n",
    "    }\n",
    "    # Trouver le nom avec la similarité la plus élevée\n",
    "    best_match = max(similarities, key=similarities.get)\n",
    "    return best_match, similarities[best_match]\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_photo_path = \"contacts_photos/TEST.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db)\n",
    "\n",
    "print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 131ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "La photo ressemble le plus à : Clem avec un score de similarité de 0.89\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:34:27.277178Z",
     "start_time": "2024-11-22T15:34:25.853657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fonction pour extraire les embeddings d'une image\n",
    "def get_embedding(image_path):\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convertir en RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Redimensionner pour correspondre à l'entrée du modèle\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # Prétraitement de l'image\n",
    "    image = preprocess_input(np.expand_dims(image, axis=0))\n",
    "    # Obtenir les embeddings\n",
    "    embedding = model.predict(image)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# Base de données : Dictionnaire avec noms et chemins des photos\n",
    "database = {\n",
    "    \"Clem\": \"contacts_photos/Clem.jpg\",\n",
    "    \"Jerem\": \"contacts_photos/Jerem.jpg\",\n",
    "}\n",
    "\n",
    "# Extraire les embeddings pour la base de données\n",
    "embeddings_db = {}\n",
    "for name, photo_path in database.items():\n",
    "    embeddings_db[name] = get_embedding(photo_path)\n",
    "\n",
    "\n",
    "# Fonction pour trouver la correspondance la plus proche avec un seuil\n",
    "def find_most_similar(new_image_path, embeddings_db, similarity_threshold=0.7):\n",
    "    # Obtenir l'embedding de la nouvelle image\n",
    "    new_embedding = get_embedding(new_image_path)\n",
    "    # Calculer les similarités\n",
    "    similarities = {\n",
    "        name: cosine_similarity(new_embedding, embedding)[0][0]\n",
    "        for name, embedding in embeddings_db.items()\n",
    "    }\n",
    "    # Trouver le nom avec la similarité la plus élevée\n",
    "    best_match = max(similarities, key=similarities.get)\n",
    "    best_score = similarities[best_match]\n",
    "\n",
    "    # Vérifier si le meilleur score dépasse le seuil\n",
    "    if best_score >= similarity_threshold:\n",
    "        return best_match, best_score\n",
    "    else:\n",
    "        return None, best_score\n",
    "\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_photo_path = \"contacts_photos/TEST.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db, similarity_threshold=0.8)\n",
    "\n",
    "if match:\n",
    "    print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n",
    "else:\n",
    "    print(f\"La photo ne correspond à aucune personne connue (score maximum : {score:.2f})\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_photo_path = \"contacts_photos/TEST2.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db, similarity_threshold=0.8)\n",
    "\n",
    "if match:\n",
    "    print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n",
    "else:\n",
    "    print(f\"La photo ne correspond à aucune personne connue (score maximum : {score:.2f})\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_photo_path = \"contacts_photos/Mathis.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db, similarity_threshold=0.8)\n",
    "\n",
    "if match:\n",
    "    print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n",
    "else:\n",
    "    print(f\"La photo ne correspond à aucune personne connue (score maximum : {score:.2f})\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_photo_path = \"contacts_photos/Romeo.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db, similarity_threshold=0.8)\n",
    "\n",
    "if match:\n",
    "    print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n",
    "else:\n",
    "    print(f\"La photo ne correspond à aucune personne connue (score maximum : {score:.2f})\")\n"
   ],
   "id": "efaca18f3e3ebe9f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "La photo ressemble le plus à : Clem avec un score de similarité de 0.89\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "La photo ressemble le plus à : Jerem avec un score de similarité de 0.85\n",
      "1/1 [==============================] - 0s 159ms/step\n",
      "La photo ne correspond à aucune personne connue (score maximum : 0.77)\n",
      "1/1 [==============================] - 0s 149ms/step\n",
      "La photo ne correspond à aucune personne connue (score maximum : 0.80)\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:37:50.154333Z",
     "start_time": "2024-11-22T15:37:48.514072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fonction pour extraire les embeddings d'une image\n",
    "def get_embedding(image_path):\n",
    "    # Charger l'image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Convertir en RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Redimensionner pour correspondre à l'entrée du modèle\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # Prétraitement de l'image\n",
    "    image = preprocess_input(np.expand_dims(image, axis=0))\n",
    "    # Obtenir les embeddings\n",
    "    embedding = model.predict(image)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "# Base de données : Dictionnaire avec noms et chemins des photos\n",
    "database = {\n",
    "    \"Clem\": \"contacts_photos/Clem.jpg\",\n",
    "    \"Jerem\": \"contacts_photos/Jerem.jpg\",\n",
    "    \"Angelina Jolie\": \"CelebrityFacesDataset/Angelina Jolie/001_fe3347c0.jpg\",\n",
    "    \"Brad Pitt\": \"CelebrityFacesDataset/Brad Pitt/001_c04300ef.jpg\",\n",
    "    \"Denzel Washington\": \"CelebrityFacesDataset/Denzel Washington/001_d3323f3c.jpg\",\n",
    "    \"Hugh Jackman\": \"CelebrityFacesDataset/Hugh Jackman/001_9adc92c2.jpg\",\n",
    "    \"Jennifer Lawrence\": \"CelebrityFacesDataset/Jennifer Lawrence/001_21a7d5e6.jpg\",\n",
    "    #\"Johnny Depp\": \"CelebrityFacesDataset/Johnny Depp/001_7b3b3b3b.jpg\",\n",
    "}\n",
    "\n",
    "# Extraire les embeddings pour la base de données\n",
    "embeddings_db = {}\n",
    "for name, photo_path in database.items():\n",
    "    embeddings_db[name] = get_embedding(photo_path)\n",
    "\n",
    "\n",
    "# Fonction pour trouver la correspondance la plus proche avec un seuil\n",
    "def find_most_similar(new_image_path, embeddings_db, similarity_threshold=0.7):\n",
    "    # Obtenir l'embedding de la nouvelle image\n",
    "    new_embedding = get_embedding(new_image_path)\n",
    "    # Calculer les similarités\n",
    "    similarities = {\n",
    "        name: cosine_similarity(new_embedding, embedding)[0][0]\n",
    "        for name, embedding in embeddings_db.items()\n",
    "    }\n",
    "    # Trouver le nom avec la similarité la plus élevée\n",
    "    best_match = max(similarities, key=similarities.get)\n",
    "    best_score = similarities[best_match]\n",
    "\n",
    "    # Vérifier si le meilleur score dépasse le seuil\n",
    "    if best_score >= similarity_threshold:\n",
    "        return best_match, best_score\n",
    "    else:\n",
    "        return None, best_score"
   ],
   "id": "231dcf5a2ea70fed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 185ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 209ms/step\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T15:39:21.236337Z",
     "start_time": "2024-11-22T15:39:20.264051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exemple d'utilisation\n",
    "new_photo_path = \"contacts_photos/TEST.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db, similarity_threshold=0.5)\n",
    "\n",
    "if match:\n",
    "    print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n",
    "else:\n",
    "    print(f\"La photo ne correspond à aucune personne connue (score maximum : {score:.2f})\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_photo_path = \"contacts_photos/TEST2.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db, similarity_threshold=0.5)\n",
    "\n",
    "if match:\n",
    "    print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n",
    "else:\n",
    "    print(f\"La photo ne correspond à aucune personne connue (score maximum : {score:.2f})\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_photo_path = \"CelebrityFacesDataset/Angelina Jolie/002_8f8da10e.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db, similarity_threshold=0.5)\n",
    "\n",
    "if match:\n",
    "    print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n",
    "else:\n",
    "    print(f\"La photo ne correspond à aucune personne connue (score maximum : {score:.2f})\")\n",
    "\n",
    "# Exemple d'utilisation\n",
    "new_photo_path = \"CelebrityFacesDataset/Brad Pitt/012_8de7a736.jpg\"\n",
    "match, score = find_most_similar(new_photo_path, embeddings_db, similarity_threshold=0.5)\n",
    "\n",
    "if match:\n",
    "    print(f\"La photo ressemble le plus à : {match} avec un score de similarité de {score:.2f}\")\n",
    "else:\n",
    "    print(f\"La photo ne correspond à aucune personne connue (score maximum : {score:.2f})\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "f64464c806c503e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 145ms/step\n",
      "La photo ressemble le plus à : Clem avec un score de similarité de 0.89\n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "La photo ressemble le plus à : Jerem avec un score de similarité de 0.85\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "La photo ressemble le plus à : Angelina Jolie avec un score de similarité de 0.74\n",
      "1/1 [==============================] - 0s 164ms/step\n",
      "La photo ressemble le plus à : Hugh Jackman avec un score de similarité de 0.67\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AAAAAAAAA",
   "id": "1cc6af3795d7fd1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T16:40:39.046197Z",
     "start_time": "2024-11-22T16:40:38.897436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import face_recognition\n",
    "\n",
    "\n",
    "def face_confidence(face_distance, face_match_threshold=0.6):\n",
    "    range = (1.0 - face_match_threshold)\n",
    "    linear_val = (1.0 - face_distance) / (range * 2.0)\n",
    "\n",
    "    if face_distance > face_match_threshold:\n",
    "        return str(round(linear_val * 100, 2)) + '%'\n",
    "    else:\n",
    "        value = (linear_val + ((1.0 - linear_val) * math.pow((linear_val - 0.5) * 2, 0.2))) * 100\n",
    "        return str(round(value, 2)) + '%'\n",
    "\n",
    "\n",
    "class FaceRecognition:\n",
    "    face_locations = []\n",
    "    face_encodings = []\n",
    "    face_names = []\n",
    "    known_face_encodings = []\n",
    "    known_face_names = []\n",
    "    process_current_frame = True\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        # encode faces\n",
    "\n",
    "    def encode_faces(self):\n",
    "        for image in os.listdir('face'):\n",
    "            face_image = face_recognition.load_image_file(f'face/{image}')\n",
    "            face_encoding = face_recognition.face_encodings(face_image)[0]\n",
    "            self.known_face_encodings.append(face_encoding)\n",
    "            self.known_face_names.append(image)\n",
    "        print(self.known_face_names)\n",
    "\n",
    "    def run_recognition(self):\n",
    "        video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "        if not video_capture.isOpened():\n",
    "            sys.exit('Camera is not available')\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            if self.process_current_frame:\n",
    "                small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "                rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "                self.face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "                self.face_encodings = face_recognition.face_encodings(rgb_small_frame, self.face_locations)\n",
    "\n",
    "                self.face_names = []\n",
    "\n",
    "                for face_encoding in self.face_encodings:\n",
    "                    matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding)\n",
    "                    name = 'Unknown'\n",
    "                    confidence = 'Unknown'\n",
    "                    face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "\n",
    "                    if matches[best_match_index]:\n",
    "                        name = self.known_face_names[best_match_index]\n",
    "                        confidence = face_confidence(face_distances[best_match_index])\n",
    "\n",
    "                    self.face_names.append(f'{name} ({confidence})')\n",
    "            self.process_current_frame = not self.process_current_frame\n",
    "\n",
    "            for (top, right, bottom, left), name in zip(self.face_locations, self.face_names):\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), -1)\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 1)\n",
    "            cv2.imshow('Face Recognition', frame)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fr = FaceRecognition()\n",
    "\n",
    "    fr.run_recognition()"
   ],
   "id": "bc66c6d8c717cf28",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mface_recognition\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mface_confidence\u001B[39m(face_distance, face_match_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.6\u001B[39m):\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mrange\u001B[39m \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m face_match_threshold)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T16:39:30.791738Z",
     "start_time": "2024-11-22T16:39:30.688205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import face_recognition\n",
    "\n",
    "def face_confidence(face_distance, face_match_threshold=0.6):\n",
    "    range_val = (1.0 - face_match_threshold)\n",
    "    linear_val = (1.0 - face_distance) / (range_val * 2.0)\n",
    "\n",
    "    if face_distance > face_match_threshold:\n",
    "        return str(round(linear_val * 100, 2)) + '%'\n",
    "    else:\n",
    "        value = (linear_val + ((1.0 - linear_val) * math.pow((linear_val - 0.5) * 2, 0.2))) * 100\n",
    "        return str(round(value, 2)) + '%'\n",
    "\n",
    "class FaceRecognition:\n",
    "    def __init__(self):\n",
    "        self.face_locations = []\n",
    "        self.face_encodings = []\n",
    "        self.face_names = []\n",
    "        self.known_face_encodings = []\n",
    "        self.known_face_names = []\n",
    "        self.process_current_frame = True\n",
    "\n",
    "        self.encode_faces()\n",
    "\n",
    "    def encode_faces(self):\n",
    "        faces_dir = 'faces'  # Ensure the directory is named correctly and exists\n",
    "        if not os.path.exists(faces_dir):\n",
    "            print(f\"Directory '{faces_dir}' does not exist.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        for image_name in os.listdir(faces_dir):\n",
    "            image_path = os.path.join(faces_dir, image_name)\n",
    "            try:\n",
    "                face_image = face_recognition.load_image_file(image_path)\n",
    "                face_encoding = face_recognition.face_encodings(face_image)[0]\n",
    "                self.known_face_encodings.append(face_encoding)\n",
    "                self.known_face_names.append(os.path.splitext(image_name)[0])\n",
    "            except IndexError:\n",
    "                print(f\"No face found in image {image_name}. Skipping.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_name}: {e}\")\n",
    "\n",
    "        print(\"Encoded faces:\", self.known_face_names)\n",
    "\n",
    "    def run_recognition(self):\n",
    "        video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "        if not video_capture.isOpened():\n",
    "            sys.exit('Camera is not available')\n",
    "\n",
    "        while True:\n",
    "            ret, frame = video_capture.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Failed to capture frame from camera. Exiting.\")\n",
    "                break\n",
    "\n",
    "            if self.process_current_frame:\n",
    "                small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "                rgb_small_frame = small_frame[:, :, ::-1]\n",
    "\n",
    "                self.face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "                self.face_encodings = face_recognition.face_encodings(rgb_small_frame, self.face_locations)\n",
    "\n",
    "                self.face_names = []\n",
    "\n",
    "                for face_encoding in self.face_encodings:\n",
    "                    matches = face_recognition.compare_faces(self.known_face_encodings, face_encoding)\n",
    "                    name = 'Unknown'\n",
    "                    confidence = 'Unknown'\n",
    "\n",
    "                    face_distances = face_recognition.face_distance(self.known_face_encodings, face_encoding)\n",
    "                    best_match_index = np.argmin(face_distances)\n",
    "\n",
    "                    if matches[best_match_index]:\n",
    "                        name = self.known_face_names[best_match_index]\n",
    "                        confidence = face_confidence(face_distances[best_match_index])\n",
    "\n",
    "                    self.face_names.append(f'{name} ({confidence})')\n",
    "\n",
    "            self.process_current_frame = not self.process_current_frame\n",
    "\n",
    "            for (top, right, bottom, left), name in zip(self.face_locations, self.face_names):\n",
    "                top *= 4\n",
    "                right *= 4\n",
    "                bottom *= 4\n",
    "                left *= 4\n",
    "\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "                cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), -1)\n",
    "                cv2.putText(frame, name, (left + 6, bottom - 6), cv2.FONT_HERSHEY_DUPLEX, 0.8, (255, 255, 255), 1)\n",
    "\n",
    "            cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                break\n",
    "\n",
    "        video_capture.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fr = FaceRecognition()\n",
    "    fr.run_recognition()"
   ],
   "id": "f499e8f3d585066d",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'face_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmath\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mface_recognition\u001B[39;00m  \u001B[38;5;66;03m# Ensure this library is installed\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mface_confidence\u001B[39m(face_distance, face_match_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.6\u001B[39m):\n\u001B[0;32m      9\u001B[0m     range_val \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m-\u001B[39m face_match_threshold)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'face_recognition'"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
